{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa8401d73c7a19e1a43fdd6a992ea9dcb60039a2"
   },
   "source": [
    "# Overview\n",
    "The notebook shows how to extract the segmentation map for the ships, augment the images and train a simple DNN model to detect them. A few additional tweaks like balancing the ship-count out a little better have been done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6cd9d5ad61ffe3b8858769f20a5f9493f024a56"
   },
   "source": [
    "## Model Parameters\n",
    "We might want to adjust these later (or do some hyperparameter optimizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "301a5d939c566d1487a049bb2554d09b592b18b1"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EDGE_CROP = 16\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'DECONV'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = (1, 1)\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (2, 2)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 1000\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 1\n",
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util.montage import montage2d as montage\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ship_dir = '../input'\n",
    "train_image_dir = os.path.join(ship_dir, 'train')\n",
    "test_image_dir = os.path.join(ship_dir, 'test')\n",
    "import gc; gc.enable() # memory is tight\n",
    "\n",
    "from skimage.morphology import label\n",
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "3ca7119188fbb4c6540d9df55f5833b55435287e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131030 masks found\n",
      "104070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>101361 1 102128 3 102896 4 103663 6 104430 9 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00021ddc3.jpg</td>\n",
       "      <td>74444 4 75212 4 75980 4 76748 4 77517 3 78285 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "2  00021ddc3.jpg  101361 1 102128 3 102896 4 103663 6 104430 9 1...\n",
       "3  00021ddc3.jpg  95225 2 95992 5 96760 7 97527 9 98294 9 99062 ...\n",
       "4  00021ddc3.jpg  74444 4 75212 4 75980 4 76748 4 77517 3 78285 ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = pd.read_csv(os.path.join('../input/',\n",
    "                                 'train_ship_segmentations.csv'))\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fdedd5965f47f84aa8f3aab1cad978512781a1cc"
   },
   "source": [
    "# Make sure encode/decode works\n",
    "Given the process\n",
    "$$  RLE_0 \\stackrel{Decode}{\\longrightarrow} \\textrm{Image}_0 \\stackrel{Encode}{\\longrightarrow} RLE_1 \\stackrel{Decode}{\\longrightarrow} \\textrm{Image}_1 $$\n",
    "We want to check if/that\n",
    "$ \\textrm{Image}_0 \\stackrel{?}{=} \\textrm{Image}_1 $\n",
    "We could check the RLEs as well but that is more tedious. Also depending on how the objects have been labeled we might have different counts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0081fd6f387abd7c05eb35f29575a2ee6ddc2236"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/skimage/measure/_label.py:4: skimage_deprecation: Call to deprecated function ``label``. Use ``skimage.measure.label`` instead.\n",
      "  return _label(input, neighbors, background, return_num)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Decoding->Encoding RLE_0: 9 -> RLE_1: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "rle_0 = masks.query('ImageId==\"00021ddc3.jpg\"')['EncodedPixels']\n",
    "img_0 = masks_as_image(rle_0)\n",
    "ax1.imshow(img_0[:, :, 0])\n",
    "ax1.set_title('Image$_0$')\n",
    "rle_1 = multi_rle_encode(img_0)\n",
    "img_1 = masks_as_image(rle_1)\n",
    "ax2.imshow(img_1[:, :, 0])\n",
    "ax2.set_title('Image$_1$')\n",
    "print('Check Decoding->Encoding',\n",
    "      'RLE_0:', len(rle_0), '->',\n",
    "      'RLE_1:', len(rle_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40cb72e241c0c3d8bc245b4e3c663b4a835b0011"
   },
   "source": [
    "# Split into training and validation groups\n",
    "We stratify by the number of boats appearing so we have nice balances in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c4f008bf6898518fd371de013418f936edaa09f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>has_ship_vec</th>\n",
       "      <th>file_size_kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73632</th>\n",
       "      <td>b4ed60224.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>371.644531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62840</th>\n",
       "      <td>9a5749e5f.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>106.860352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75444</th>\n",
       "      <td>b9674d0f6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>110.474609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49454</th>\n",
       "      <td>797836c35.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>126.569336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>02f0f0abb.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>168.121094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  ships  has_ship has_ship_vec  file_size_kb\n",
       "73632  b4ed60224.jpg      0       0.0        [0.0]    371.644531\n",
       "62840  9a5749e5f.jpg      0       0.0        [0.0]    106.860352\n",
       "75444  b9674d0f6.jpg      0       0.0        [0.0]    110.474609\n",
       "49454  797836c35.jpg      1       1.0        [1.0]    126.569336\n",
       "1255   02f0f0abb.jpg      0       0.0        [0.0]    168.121094"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "# some files are too small/corrupt\n",
    "unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n",
    "                                                               os.stat(os.path.join(train_image_dir, \n",
    "                                                                                    c_img_id)).st_size/1024)\n",
    "unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\n",
    "unique_img_ids['file_size_kb'].hist()\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "unique_img_ids.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "871720221ac25f7f9408bfe01aeb4ccb95edbd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91008 training masks\n",
      "39006 validation masks\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.3, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c21d5bff04bf9180463969ac120379345745ed03"
   },
   "source": [
    "### Examine Number of Ship Images\n",
    "Here we examine how often ships appear and replace the ones without any ships with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "2612fa47c7e9fdcaa7aa720c4e15fc86fd65d69a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f527321bb70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['ships'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef8115a80749ac47f295e9a70217a5553970c2b3"
   },
   "source": [
    "# Undersample Empty Images\n",
    "Here we undersample the empty images to get a better balanced group with more ships to try and segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cf0bb261eda957cb0a12a330260e1390c57c8c9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+2)//3)\n",
    "balanced_train_df = train_df.groupby('grouped_ship_count').apply(lambda x: x.sample(1500))\n",
    "balanced_train_df['ships'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a3fb9fe33d81374c7bd836f5bc86a1df89190805"
   },
   "source": [
    "# Decode all the RLEs into Images\n",
    "We make a generator to produce batches of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6181ac51577e5636995e38a9e29311cf47f513ca",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1983738da75b031f2bec8ba36db01c095e7c5d59",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = make_image_gen(balanced_train_df)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4396cd28ddd2e4c8076fcb165e9b61e3baeeeb7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
    "batch_rgb = montage_rgb(train_x)\n",
    "batch_seg = montage(train_y[:, :, :, 0])\n",
    "ax1.imshow(batch_rgb)\n",
    "ax1.set_title('Images')\n",
    "ax2.imshow(batch_seg)\n",
    "ax2.set_title('Segmentations')\n",
    "ax3.imshow(mark_boundaries(batch_rgb, \n",
    "                           batch_seg.astype(int)))\n",
    "ax3.set_title('Outlined Ships')\n",
    "fig.savefig('overview.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f47639c987a10ebcb53e51f55aa8a11c98fa860"
   },
   "source": [
    "# Make the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30cb02a2a7103a9d66e90f701991199de1e5b73e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8f65e7942816fb75b687a549dc1d5cc48d00e21"
   },
   "source": [
    "# Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d94dc8163528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m dg_args = dict(featurewise_center = False, \n\u001b[1;32m      3\u001b[0m                   \u001b[0msamplewise_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mrotation_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mwidth_shift_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 15, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "# brightness can be problematic since it seems to change the labels differently from the images \n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "        g_y = label_gen.flow(in_y, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "\n",
    "        yield next(g_x)/255.0, next(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6122ccb9e58bfac6fa5e11c86121e78d9e5151b1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "# only keep first 9 samples to examine in detail\n",
    "t_x = t_x[:9]\n",
    "t_y = t_y[:9]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "ax1.imshow(montage_rgb(t_x), cmap='gray')\n",
    "ax1.set_title('images')\n",
    "ax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')\n",
    "ax2.set_title('ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33300c4f03b6600da7b418f775d11d7ebf76a35a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba08494eb9736ec3556b7c879143cdcdea89febf"
   },
   "source": [
    "# Build a Model\n",
    "Here we use a slight deviation on the U-Net standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2687377309d3cbbab1197f4eccd2b50ab996f5a6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "# Build U-Net model\n",
    "def upsample_conv(filters, kernel_size, strides, padding):\n",
    "    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n",
    "def upsample_simple(filters, kernel_size, strides, padding):\n",
    "    return layers.UpSampling2D(strides)\n",
    "\n",
    "if UPSAMPLE_MODE=='DECONV':\n",
    "    upsample=upsample_conv\n",
    "else:\n",
    "    upsample=upsample_simple\n",
    "    \n",
    "input_img = layers.Input(t_x.shape[1:], name = 'RGB_Input')\n",
    "pp_in_layer = input_img\n",
    "if NET_SCALING is not None:\n",
    "    pp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\n",
    "    \n",
    "pp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\n",
    "pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n",
    "\n",
    "c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (pp_in_layer)\n",
    "c1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = layers.MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = layers.MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = layers.MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "\n",
    "c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
    "c5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = upsample(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = layers.concatenate([u6, c4])\n",
    "c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = upsample(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = layers.concatenate([u7, c3])\n",
    "c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = upsample(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = layers.concatenate([u8, c2])\n",
    "c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = upsample(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = layers.concatenate([u9, c1], axis=3)\n",
    "c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "d = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "if NET_SCALING is not None:\n",
    "    d = layers.UpSampling2D(NET_SCALING)(d)\n",
    "\n",
    "seg_model = models.Model(inputs=[input_img], outputs=[d])\n",
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1678069aa8013510264ba898291c6ae2dce88a76",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7282d18de3aff1cee12ff89b7d511a391702814f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "                      mode=\"max\", \n",
    "                      patience=20) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b67d808c0b8c7e28bff41e6d3858ff6f09dd626",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step_count = min(MAX_TRAIN_STEPS, balanced_train_df.shape[0]//BATCH_SIZE)\n",
    "aug_gen = create_aug_gen(make_image_gen(balanced_train_df))\n",
    "loss_history = [seg_model.fit_generator(aug_gen, \n",
    "                             steps_per_epoch=step_count, \n",
    "                             epochs=10, \n",
    "                             validation_data=(valid_x, valid_y),\n",
    "                             callbacks=callbacks_list,\n",
    "                            workers=1 # the generator is not very thread safe\n",
    "                                       )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a168c8b1af446b800f6129104906003ededd61c4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_loss(loss_history):\n",
    "    epich = np.cumsum(np.concatenate(\n",
    "        [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(22, 10))\n",
    "    _ = ax1.plot(epich,\n",
    "                 np.concatenate([mh.history['loss'] for mh in loss_history]),\n",
    "                 'b-',\n",
    "                 epich, np.concatenate(\n",
    "            [mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
    "    ax1.legend(['Training', 'Validation'])\n",
    "    ax1.set_title('Loss')\n",
    "\n",
    "    _ = ax2.plot(epich, np.concatenate(\n",
    "        [mh.history['true_positive_rate'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_true_positive_rate'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax2.legend(['Training', 'Validation'])\n",
    "    ax2.set_title('True Positive Rate\\n(Positive Accuracy)')\n",
    "    \n",
    "    _ = ax3.plot(epich, np.concatenate(\n",
    "        [mh.history['binary_accuracy'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_binary_accuracy'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax3.legend(['Training', 'Validation'])\n",
    "    ax3.set_title('Binary Accuracy (%)')\n",
    "    \n",
    "    _ = ax4.plot(epich, np.concatenate(\n",
    "        [mh.history['dice_coef'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_dice_coef'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax4.legend(['Training', 'Validation'])\n",
    "    ax4.set_title('DICE')\n",
    "\n",
    "show_loss(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce1167e9f09200f537e61f93f486168a13be1711",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seg_model.load_weights(weight_path)\n",
    "seg_model.save('seg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "275b411dc97a350aacaba46c8562efcf2658b1a7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y = seg_model.predict(valid_x)\n",
    "print(pred_y.shape, pred_y.min(), pred_y.max(), pred_y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a4fd2ca0cf47ba069a314356bf74c7b531c56ac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax.hist(pred_y.ravel(), np.linspace(0, 1, 10))\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0018ab172d18936f8cc2c5df33d2f840dc16bf4f"
   },
   "source": [
    "# Prepare Full Resolution Model\n",
    "Here we account for the scaling so everything can happen in the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17408f0ee8dc16149b8eff0447a1427ab3ed82ba",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if IMG_SCALING is not None:\n",
    "    fullres_model = models.Sequential()\n",
    "    fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n",
    "    fullres_model.add(seg_model)\n",
    "    fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n",
    "else:\n",
    "    fullres_model = seg_model\n",
    "fullres_model.save('fullres_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "17edb177402ae51651692511827a7e9d60646533"
   },
   "source": [
    "# Run the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4911811f267f9f3397a58902da9e75c6f261ad40",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_paths = os.listdir(test_image_dir)\n",
    "print(len(test_paths), 'test images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73ef7b3b2a74bf64968c79b4005075d4f0e23143",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(20, 2, figsize = (10, 40))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "for (ax1, ax2), c_img_name in zip(m_axs, test_paths):\n",
    "    c_path = os.path.join(test_image_dir, c_img_name)\n",
    "    c_img = imread(c_path)\n",
    "    first_img = np.expand_dims(c_img, 0)/255.0\n",
    "    first_seg = fullres_model.predict(first_img)\n",
    "    ax1.imshow(first_img[0])\n",
    "    ax1.set_title('Image')\n",
    "    ax2.imshow(first_seg[0, :, :, 0], vmin = 0, vmax = 1)\n",
    "    ax2.set_title('Prediction')\n",
    "fig.savefig('test_predictions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11a6c6615131ff8c317f95a5097b46565ef21121",
    "collapsed": true
   },
   "source": [
    "# Submission\n",
    "Since gneerating the submission takes a long time and quite a bit of memory we run it in a seperate kernel located at https://www.kaggle.com/kmader/from-trained-u-net-to-submission-part-2 \n",
    "That kernel takes the model saved in this kernel and applies it to all the test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
